{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Take-notice!\" data-toc-modified-id=\"Take-notice!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Take notice!</a></span></li><li><span><a href=\"#Sentiment-Analysis\" data-toc-modified-id=\"Sentiment-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sentiment Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bring-in-the-libraries\" data-toc-modified-id=\"Bring-in-the-libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bring in the libraries</a></span></li></ul></li><li><span><a href=\"#Twitter-with-tweepy\" data-toc-modified-id=\"Twitter-with-tweepy-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Twitter with tweepy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tweets-by-username\" data-toc-modified-id=\"Tweets-by-username-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tweets by username</a></span></li><li><span><a href=\"#Tweets-by-keyword\" data-toc-modified-id=\"Tweets-by-keyword-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Tweets by keyword</a></span></li><li><span><a href=\"#Tweets-by-keyword-and-place\" data-toc-modified-id=\"Tweets-by-keyword-and-place-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Tweets by keyword and place</a></span></li></ul></li><li><span><a href=\"#The-tweet-object\" data-toc-modified-id=\"The-tweet-object-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The tweet object</a></span><ul class=\"toc-item\"><li><span><a href=\"#Word-Cloud\" data-toc-modified-id=\"Word-Cloud-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Word Cloud</a></span></li><li><span><a href=\"#Stop-words\" data-toc-modified-id=\"Stop-words-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Stop words</a></span></li><li><span><a href=\"#Sentiment-Analysis\" data-toc-modified-id=\"Sentiment-Analysis-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Sentiment Analysis</a></span></li><li><span><a href=\"#Choosing-colors\" data-toc-modified-id=\"Choosing-colors-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Choosing colors</a></span></li><li><span><a href=\"#Sentiment-bar-chart\" data-toc-modified-id=\"Sentiment-bar-chart-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Sentiment bar chart</a></span></li><li><span><a href=\"#Sentiment-histogram\" data-toc-modified-id=\"Sentiment-histogram-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Sentiment histogram</a></span></li></ul></li><li><span><a href=\"#Let's-make-a-function!\" data-toc-modified-id=\"Let's-make-a-function!-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Let's make a function!</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "<h1>Take notice!</h1>\n",
    "<ul>\n",
    "    <li>This class will be recorded</li>\n",
    "</ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "For this lab, we will look at a way to use python to analyze qualitative data. This lab will:\n",
    "\n",
    "- import twitter data\n",
    "- create word clouds\n",
    "- conduct sentiment analysis\n",
    "\n",
    "We will use the following libraries:\n",
    "\n",
    "- [tweepy](http://docs.tweepy.org/en/v3.9.0/getting_started.html) to bring twitter into our notebooks\n",
    "- [word_cloud](https://github.com/amueller/word_cloud) to create word clouds\n",
    "- [textblob](https://textblob.readthedocs.io/en/dev/) for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bring in the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the regulars\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to get tweets\n",
    "import tweepy as tw\n",
    "\n",
    "# for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# word clouds\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Twitter with tweepy\n",
    "\n",
    "In order to use twitter's api, you will need a [developer's account](https://developer.twitter.com/en/apply-for-access). You will then have the ability to generate the tokens needed to use their API.\n",
    "\n",
    "- http://docs.tweepy.org/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# your twitter keys/secrets/tokens\n",
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= ''\n",
    "access_token_secret= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# authenticate thyself with twitter\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tweets by username\n",
    "- http://docs.tweepy.org/en/latest/api.html#API.user_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.user_timeline, id='POTUS', tweet_mode='extended').items(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(str(tweet.created_at) + ': ' + tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tweets by keyword\n",
    "\n",
    "* search parameters: http://docs.tweepy.org/en/latest/api.html#search-methods\n",
    "* [rules and filetering](https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/overview/standard-operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# search query\n",
    "searchterm = 'vaccine'\n",
    "\n",
    "# filter out retweets (optional of course)\n",
    "q = searchterm + \" -filter:retweets\"\n",
    "\n",
    "# how many?\n",
    "max_tweets = 500\n",
    " \n",
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=q, \n",
    "                   tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tweets by keyword and place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "                   q=q,\n",
    "                   geocode='34.068921,-118.4473751,50km', \n",
    "                   tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(str(tweet.created_at) + ': ' + tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The tweet object\n",
    "\n",
    "So what does tweepy return? It returns an item iterator that allows us to loop and extract information. However, for reasons that I am unable to verify, the item iterator that is returned by the `tw.Cursor` function can only run a single loop operation before it mysteriously disappears (if anybody can figure this one out, let me know!). For that reason, let's run the search again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# search twitter (again)\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=q,\n",
    "                   geocode='34.068921,-118.4473751,50km', \n",
    "                   tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The tweet object is in *json* format. We can convert it into a dataframe for easier access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# convert json tweets to dataframe\n",
    "json_data = [tweet._json for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fields?\n",
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That's a lot of columns! Twitter saves a ton of metadata for each tweet... Let's clean this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# trim the columns\n",
    "df = df[['created_at','full_text','user.screen_name','user.profile_image_url_https']]\n",
    "\n",
    "# rename the columns\n",
    "df.columns = ['created_at','text','screen_name','profile_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# override the default so that we can see the entire text in the column\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just for fun, let's convert the profile image url's into actual images. This is somewhat of a hack, and only works with the applied code below (ie, it's not baked into the dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# library to display html images\n",
    "from IPython.display import Image, HTML\n",
    "\n",
    "# function to convert url to html image\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\"/>'\n",
    "\n",
    "HTML(df.to_html(escape=False ,formatters=dict(profile_image=path_to_image_html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Now it's your turn! Get creative and create your own twitter search queries on matters that interest you. Make sure that you end up with a dataframe named \"df\" to use for the word cloud below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Cloud\n",
    "Word clouds are great to visually display word clusters. The algorithms are simple. More word frequency, larger font size, less frequent words, smaller fonts sizes.\n",
    "\n",
    "We will use the [word_cloud library](https://github.com/amueller/word_cloud).\n",
    "\n",
    "First though, we need to clean up the tweets. Tweets are notorious for having strange characters and emoji's!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# function to clean tweets using regular expressions\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# an example of cleaning a tweet\n",
    "tweet = df.sample().text.values[0]\n",
    "print(tweet)\n",
    "clean_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a new column for the clean text\n",
    "df['clean_text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# loop and add the cleaned up text to the new column\n",
    "for i, row in df.iterrows():\n",
    "    clean = clean_tweet(row.text)\n",
    "    df.at[i,'clean_text'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(5)[['text','clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great. Every tweet has been cleaned up. In order to create a word cloud, we need to create a single variable that has every word in every tweet from our twitter dataframe. We then feed that to the world cloud factory that will generate the word cloud for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# now put every word from every tweet into a single variable\n",
    "all_text = ' '.join(df['clean_text'])\n",
    "all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# WordCloud comes with default stopwords. \n",
    "list(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Append the query term to this list\n",
    "stop_words = [searchterm] + list(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create the word cloud\n",
    "wordcloud = WordCloud(width=1200, \n",
    "                      height=800,\n",
    "                      background_color=\"white\",\n",
    "                      stopwords=stop_words).generate(all_text)\n",
    "\n",
    "# Display the WordCloud                    \n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "<img src=\"https://monkeylearn.com/static/3ca10d6ce5dc6922836f278aef38f765/50bf7/what-is-sentiment-analysis6%402x.png\" width=400>\n",
    "\n",
    "[source](https://monkeylearn.com/sentiment-analysis/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For sentiment analysis, we will use the [textblob](https://textblob.readthedocs.io/en/dev/) python library.\n",
    "\n",
    "The sentiment property returns a tuple of the form `Sentiment(polarity, subjectivity)`. The polarity score ranges from -1 (most negative) to +1 (most positive). The subjectivity ranges from 0 to 1, where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Let's test this out on a random tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get a random tweet\n",
    "tweet = df.sample().clean_text.values[0]\n",
    "print(tweet)\n",
    "\n",
    "# analyze the tweet\n",
    "a = TextBlob(tweet)\n",
    "\n",
    "# results\n",
    "a.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create an new (empty) column for polarity\n",
    "df['polarity']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# loop through every row and add the polarity value in our new column\n",
    "for i, row in df.iterrows():\n",
    "    a = TextBlob(row.clean_text)\n",
    "    df.at[i,'polarity'] = a.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[['clean_text','polarity']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's quantify the results. Tweets are either positive, neutral, or negative, so let's give them categorical values.\n",
    "\n",
    "Numpy has a convenient function `.select` that allows you to generate a categorical ranking based on conditional arguments on a given column. In other words, we can assign tweets to be \"positive\" or \"negative\" based on their polarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df['polarity'] < -0.2), # very negative\n",
    "    (df['polarity'] < 0) & (df['polarity'] >= -0.2),   # negative\n",
    "    (df['polarity'] == 0),  # neutral\n",
    "    (df['polarity'] > 0) & (df['polarity'] <= 0.2),    # positive\n",
    "    (df['polarity'] > 0.2)  # very positive\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [\n",
    "    'very negative', \n",
    "    'negative', \n",
    "    'neutral', \n",
    "    'positive',\n",
    "    'very positive'\n",
    "    ]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['sentiment'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# display updated DataFrame\n",
    "df.sample(5)[['clean_text','polarity','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing colors\n",
    "\n",
    "The OSMNx library has a useful function that extracts colors from a cmap color sequence.\n",
    "\n",
    "- cmap colors: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "- OSMNx get_colors: https://osmnx.readthedocs.io/en/stable/osmnx.html#osmnx.plot.get_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a 5 colors from sequential color bar\n",
    "sentiment_colors = ox.plot.get_colors(5,cmap='PiYG',return_hex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# bar chart\n",
    "fig = px.bar(df, \n",
    "             x='sentiment',\n",
    "             width=600,\n",
    "             title='Sentiment analysis for \"'+ searchterm + '\"',\n",
    "             color='sentiment',\n",
    "             category_orders = {'sentiment':['very negative','negative','neutral','positive','very positive']},\n",
    "             color_discrete_sequence=sentiment_colors, # use the colors selected in previous cell\n",
    "            )\n",
    "# fig.update_traces(textinfo='value')\n",
    "fig.update_traces(marker_line_width=0) # gets rid of horizontal white lines\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# histogram\n",
    "num_bins = 50\n",
    "plt.figure(figsize=(10,6))\n",
    "n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of polarity for \"' + searchterm + '\"')\n",
    "\n",
    "plt.axvline(df.polarity.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "plt.text(df.polarity.mean()*1.1, max_ylim*0.9, 'Mean: {:.2f}'.format(df.polarity.mean()))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's make a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def find_tweets(q,place,distance='50km',count=500):\n",
    "    \n",
    "    #\n",
    "    # geocode the place to get coordinates\n",
    "    #\n",
    "    \n",
    "    g = ox.geocoder.geocode(place)\n",
    "    \n",
    "    # concatenate the results\n",
    "    geocode = '\"'+str(g[0])+','+str(g[1])+','+distance+'\"'\n",
    "    \n",
    "    #\n",
    "    # grab the tweets\n",
    "    #\n",
    "    \n",
    "    tweets = tw.Cursor(api.search,\n",
    "                       q=q+' -filter:retweets', # no retweets\n",
    "                       geocode=geocode, \n",
    "                       tweet_mode='extended').items(count)\n",
    "    #\n",
    "    # create a dataframe\n",
    "    #\n",
    "    \n",
    "    json_data = [tweet._json for tweet in tweets]\n",
    "    df = pd.json_normalize(json_data)\n",
    "\n",
    "    # clean it up\n",
    "    df = df[['created_at','full_text']]\n",
    "\n",
    "    # clean the text\n",
    "    df['clean_text'] = ''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        clean = clean_tweet(row.full_text)\n",
    "        df.at[i,'clean_text'] = clean\n",
    "\n",
    "    #\n",
    "    # word cloud\n",
    "    #\n",
    "    \n",
    "    # put every tweet in a single variable\n",
    "    all_text = ' '.join(df['clean_text'])\n",
    "    \n",
    "    # Create stop words\n",
    "    stop_words = [searchterm] + list(STOPWORDS)\n",
    "    \n",
    "    # create the word cloud\n",
    "    wordcloud = WordCloud(width=1200, \n",
    "                          height=800,\n",
    "                          background_color=\"white\",\n",
    "                          stopwords=stop_words).generate(all_text)\n",
    "\n",
    "    # Display the WordCloud                    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    #\n",
    "    # sentiment analysis\n",
    "    #\n",
    "    \n",
    "    df['polarity']=''\n",
    "    \n",
    "    # add polarity index to each tweet\n",
    "    for i, row in df.iterrows():\n",
    "        a = TextBlob(row.full_text)\n",
    "        df.at[i,'polarity'] = a.polarity\n",
    "    \n",
    "    # create a list of our conditions\n",
    "    conditions = [\n",
    "        (df['polarity'] < -0.2), # very negative\n",
    "        (df['polarity'] < 0) & (df['polarity'] >= -0.2),   # negative\n",
    "        (df['polarity'] == 0),  # neutral\n",
    "        (df['polarity'] > 0) & (df['polarity'] <= 0.2),    # positive\n",
    "        (df['polarity'] > 0.2)  # very positive\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [\n",
    "        'very negative', \n",
    "        'negative', \n",
    "        'neutral', \n",
    "        'positive',\n",
    "        'very positive'\n",
    "        ]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['sentiment'] = np.select(conditions, values)\n",
    "\n",
    "    #\n",
    "    # Sentiment bar chart\n",
    "    #\n",
    "    \n",
    "    # bar chart\n",
    "    fig = px.bar(df, \n",
    "                 x='sentiment',\n",
    "                 width=600,\n",
    "                 title='Sentiment analysis for \"'+ q + '\"',\n",
    "                 color='sentiment',\n",
    "                 category_orders = {'sentiment':['very negative','negative','neutral','positive','very positive']},\n",
    "                 color_discrete_sequence=sentiment_colors, # use the colors selected in previous cell\n",
    "                )\n",
    "    # fig.update_traces(textinfo='value')\n",
    "    fig.update_traces(marker_line_width=0) # gets rid of horizontal white lines\n",
    "    fig.show()\n",
    "\n",
    "    #\n",
    "    # histogram\n",
    "    # \n",
    "    \n",
    "    num_bins = 50\n",
    "    plt.figure(figsize=(10,6))\n",
    "    n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.xlabel('Polarity')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of polarity for \"' + q + '\"')\n",
    "\n",
    "    plt.axvline(df.polarity.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    min_ylim, max_ylim = plt.ylim()\n",
    "    plt.text(df.polarity.mean()*1.1, max_ylim*0.9, 'Mean: {:.2f}'.format(df.polarity.mean()))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #\n",
    "    # Show top 10 and bottom 10 tweets\n",
    "    #\n",
    "    \n",
    "    top10 = df.sort_values('polarity').head(10)[['clean_text','polarity']]\n",
    "    bottom10 = df.sort_values('polarity').tail(10)[['clean_text','polarity']]\n",
    "    \n",
    "    display('Top 10 negative tweets')\n",
    "    display(top10)\n",
    "    \n",
    "    display('Top 10 positive tweets')\n",
    "    display(bottom10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "find_tweets(q='biden',place='90095')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "327.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
